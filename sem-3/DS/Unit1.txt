

###########################################################################################################

2. What is data science ? Explain the role of Data Scienctist. 

  - Data Science 
      - Data Science is the study of data 
        to find pattern, make prediction, and help in taking better
        desicions, It uses like Statistic, Algorithm, programming to convert data into usesful
        insights.

   - Role of Data  Scienctist.
        1. Data Collection
        2. Data Cleaning 
        3. Analyzes Data 
        4. Build Models 
        5. Data Visulization 
        6. Solve Business problem 

        1. Data Collection
           - Gather data from various sources include (database, API's, etc)
        2. Data Cleaning 
           - Clean data by fixing errors, finding missing values, organize it for analysis
        3. Analyzes Data -
           - Analyzes the data to find patterns and trends using statistics .
        4. Build Models -
           - Create Predictive models using machine learning.
        5. Visulization -
           - Visulize finding using ploting graphs, charts, etc 
             to help non-technical teams understand the results.
        6. Solve Business problem 
           - Collaborate with Business teams and provide insights and recommandation based on Research
             to make better desicions.


Application of data-science -
1. Recommdation system
   - suggest movies or product based on user preference.
2. Customer Services -
   - Analyse social media 
        1. Dignolisis
            - Help doctor to monitor and dignolis
        2. Personialised Medicine -
           - Treatment based on  individual patient history
        3. Virtual Health Assistent 
           - Chatbot provide health advice and remiders
        3. Stock market -
           - Analyzes market data to make trading decisions
        4. Customer Service -
           - Chatbot handling customer inquires.
        5. Recommendation system -
           - suggest product based on user behavior.
        6. Weather Forecasting 
           - Predicts the weather based on past data.
        8. Fraud Detection  
            - Identifies suspicious activate in banking.
       
   

3. Describe any four  tools of data science.
    1. Python
    2. Pandas 
    3. Numpy
    4. Matplotlib
    5. Tableau
    6. SQL
 
 
    1. Python-
       - Popular programming lanaguage used for data-analysis and machine-learning
    2. Pandas -
       - Python libries to manage and anaylise data in tables (Dataframe)
    3. Numpy -
       - Python librires to perform numerical operation over datasets.
    4. Matplotlib -
       - Python libries for data Visulization using diffrent charts, dashborads, graphs, etc
    5. Tableau 
       - tool used to organize data 
    6. SQL -
        language for querying and managing data in relational databases
 


##########################################################################################################
5.   What are the facet / characteristics of big Data? 
      The five V of Big data are -
         1. Volume - 
            - Large amount of data.
         2. Velocity
            - Speed of data generation
         3. Variety
            - Diffrent types and format of data.
         4. Veracity
            - Data accuracy and quality.
         5. Value.
            - Usefullness of data.

##################################################################################################################
4.   What is hadoop ? Explain Hadoop ecosystem with diagram.
    - Hadoop 
      1. Hadoop is an open-souce framework 
      2. It is build on java.
      3. It is used to store and process larage amount of data across diffent
         distributed computer environment.
    
    - components of Hadoop
                1. HDFS
                2. MapReduce
                3. YARN
                4. Hive
                5. Pig
                6. Mahout
                7. Zookeeper
                8. Oozie
         
        1. HDFS 
            -  HDFS stand for Hadoop Distributed File System.
            -  It is used for storing data accross multipal computer sytems.
        2. MapReduce
            - MapReduce is used for processing data parallel accross multipal computer Systems
        3. YARN 
            - YARN stands for Yet Another Resources Negotiator
            - It is a Resources management layer of hadoop for managing and scheduling jobs.
        4. Hive
           - It is SQL for Hadoop 
           - Allow you to querry data using sql-like lanaguage
             make it easier to interact with hadoop
        5. Pig -
            Tool that help you to write data processing script with knowing complex programming.

        6. Mahout 
           - Mahout provide machine learning algorithim to process data in hadoop.

        7.  Zookeeper 
           - Helps in cordination among diffrent distributed computer system
           - provide task synchronization over system.

        8.  Oozie -
           - It perform task of scheduling jobs    

         

Diagram -

                    +-----------------------+
                    |       Clients         |   --> (Applications or Users)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |     Data Ingestion    |   
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |    Data Storage       |   --> (HDFS)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |    Data Processing    |   --> (MapReduce, Hive, Pig)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |   Resource Management |   --> (YARN)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |   Machine Learning    |   --> (Mahout)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |    Workflow & Jobs    |   --> (Oozie, Zookeeper)
                    +-----------------------+


Architecture -
    - Hadoop architecutre has three layers
      1. Storage Layer
      2. Proccesiing Layer
      3. Resource Management Layer

    1. Storage Layer
       - It is handle by HDFS
       - In this layer HDFS (Hadoop Distributed File System) split the data into blocks 
         and distribute accross diffrent computer system (nodes)

    2. Processing Layer
       - It is mostly handle by MapReduce 
       - In this layer parallel data processing accross diffrent distributed computer system (nodes) take place.

    3. Resource Management Layer
       - Handle by YARN
       - In this layer task managaing and scheduling job take places


######################################################################################################

10.  Write a note on TensorFlow.
    1. TensorFlow is popular framework for deep-learning and Machine learning.
    2. It is free and opensource framework
    3. It is develop by google brain teams
    4. It is based on python programming lanaguage.
    5. It makes machine learning easier and faster.
    6. The word TensorFlow is made up of two words 
        1. Tensor
        2. Flow 
    7. Tensor stand for multi-diminsion array
    8. Flow stand for flow of data in operation

    Advantages 
            1. Easy to use
            2. Application
            3. Scalable
            4. Machine Leaning and Deeplearning

      1 Easy to use
         - It is biginner friendly framework.
      2. Application -
        - It has wide range of applications
        - It is used in image recognation, speech recognation, natural lanaguage processing etc.
      3. Machine Learning and Deeplearning 
        - It is mainly used for deep learning but can be also used for machine leaning task.
      4. Scalable -
        - It is highly scalable it can run on both CPU and GPU
          even in mobile device.
      
#########################################################################################################

11.  Write a note on SciPy 
     1. Scipy stands for Scientifc Python
     2. It is free and opensource Framework
     3. It is based on python programming lanaguage.
     4. It is scientific computational libries of python uses numpy underneath.
     5. It is used for solving complex scientific and mathematical problems.
     6. It provide various functions for data optmizations, integrations, analysis.

     Feature -       
       1. Easy to use 
       2. Wide Application
       3. Large Community support
       4. Build over Numpy

       1. Easy to use 
         - SciPy is biginner friendly framework.

       2. Wide Application
         - It has wide range of applications in fields of data-science, biology, physics etc
           for solving mathematical and computational problems.

       3. Large Community support
         - It has large Community

       4. Build over Numpy
         - It is build over Numpy and extend the power of numpy.
     
########################################################################################################

12.  What is Numpy ? Explain its features.
    1. Numpy stand for numerical python
    2. Numpy is free and open source python libries
    3. Numpy is genral purpose python package to handle arrays
    4. Numpy support multi-dimenstion array.
    5. Numpy array is 50x faster than traditional python list
    6. Numpy written in python , c and c++ which increase its performance

  Feature -
            1. Performance
            2. Easy to Use
            3. Memory Efficent
            4. Multi-Dimention Array
            5. Open-source
            6. Mathematical function
            
    1. Performance -
       - Numpy is faster that Python List.
    2. Easy to Use -
       - Numpy syntax is easy to use and user friendly
    3. Memory Efficent 
       - Numpy uses Less memory compare to python build in data-structure.
    4. Multi-Dimention Array
       - Numpy support Multi-dimenstion array.
    5. Open-source 
       - Numpy is free and open source python package.
    6. Mathematical function
       - Provide wide range of mathematical funtion such as trignometric function,
         logarithmic function, exponatinal, sqare-root etc.

####################################################################################################################

27.  Write a note on Seabon.
     1. Seaborn is powerful data-visulization package
     2. It is free and open-source
     3. Seaborn is based on Matplotlib
     4. It support all the feature of Matplotlib
     5. It is easy and bigineer friendly package
     6. It provide set of default theme and color which 
        make it attractive .
     7. It work seamlessly with pandas dataframe.
     8. Simplify complex process of data-visulization into 
        few lines of code.

#######################################################################################
29.  Write a note on HDFS.
     1. HDFS stand for Hadoop distributed file system.
     2. Hadoop come with distributed file system called HDFS
     3. It is cost efficent
     4. It work on low cost hardware. 
     5. It is highly scalable models
     6. It is ideal for large file.

     Components of HDFS
       1. Block
       2. Name Node
       3. Data Node
      1. Block -
        - Block store the data 
        - It has default 128 mb memory

      2.Name Node
        - Name Node manage the file-system meta-data (like, name, permission, etc)
      3. Data Node
        - they store the data blocks
        - they retrive and send blocks when request by client.
        
###########################################################################################
53.  Write a note on matplotlib.
     1. Matplotlib is powerful data-visulization package.
     2. It is free and open-source
     3. It used in data-visulization task.
     4. It support varous plotting include
        - line plots.
        - scatter plots
        - graphs
        - charts,
        - histogram , etc
     5. It is easy and bigineer friendly package
     6. Simplify complex process of data-visulization into 
        few lines of code.
      
###########################################################################################

42.  Write a note Keras.

   1. Keras is popular and powerful framework for Neural Network.
   2. It is free and opensource
   3. It is develop by one google engineering
   4. It is based on python programming.
   5. It is highly scalable it can run on both CPU and GPU 
   6. Support any Architecture.
   7. It is easy to learn package
   8. It is easy to use package make it 
   9. Support fast proto-typing.

############################################################################################

43.  Write a note on Pytorch.
    1. Pytourch is popular framework for for deeplearning.
    2. It is free and opensource framework
    3. It is build using  python programming.
    4. It is develop by facebook.
    5. It is easy to use framework
    6. It is based on torch libries.
    7. Pytorch is completly pythonic
    8. Easy to create neural network models
    9. It is easy in building an extreme complex neural network.
    10. Higly flexible , we can use it as per are requirements.

#############################################################################################

44.  Write a note on AutoML.
    1. AutoML stands for Automated Machine Learning.
    2. It is the process of automating the process of 
       machine learning to solve real world problems.
    3. AutoML is a technology that automates the process of building machine learning models
    4. It allow people without expertise in machine learning to create powerful machine learning models.
    5. It automate the manual task required for building model and 
       save time.
    6. This are some automML platforms
        1. Google Cloud AutoML.
        2. Microsoft Auzure AutoML 
        3. AWS AutoML., etc.

##############################################################################################

58.  Write a note on Colab and Kaggle.
   Coalb -
     1. Google Colab is free and opensource online tool.
     2. It is use to run and write python code.
     3. Provide free access to GPU.
     4. No need to setup, everything is ready to use.
     5. Supprot Python libries like TensorFlow, Pytorch, etc.
     6. Can able to share via link.

   Kaggle -
     1. Kaggel is also free and opensource online tool
     2. It also provide free access to GPU.
     3. Run in browser,
     4. We are able to share our code via link
     5. Write and run code online. 
     6. Best for datastes 

#################################################################################################
48.  Write a note on Artificial Neural Network. ANN
49.  Write a note on Convolutional Neural Network. CNN

   1. Artificial Neural Network -
      1. It does not allow paramter sharing.
      2. Work with tabular data and text data.
      3. Required fixed input
      4. ANN can experience vanishing.
      5. Does not Capture spatial relationships
      6. Less powerfull compare to CNN.

      Application - 
         Eg- . Used in face recognation, computer vision.

   2. Convolutional Neural Network
      1. It allow paramter sharing.
      2. Work with image data.
      3. Required fixed input in forms of image.
      4. CNN can experience vanishing.
      5. Capture spatial relationships.
      6. More powerfull compare to ANN.

      Application -
         Eg - Image recognation, Computer vision.

################################################################################################
37.  Write a note on machine learning lifecycle.

      1. Collect Data: 
         -  Collect necessary data.
      2. Clean Data:
         -  Clean and format data.
      3. Select Model: 
         - Choose an algorithm.
      4. Train Model: 
         - Train the model on the data.
      5. Evaluate Model: 
         - Check the model's performance.
      6. Tune Model: 
         - Optimize settings to improve accuracy.
      7. Deploy Model
         - Put the model into use.
      8. Monitor Model:
         - Monitor the model to keep it up to date.

################################################################################################
19.  Write a note on Anaconda and Jupyter Notebook and pip.
   1. Anaconda -
      1. Anaconda is free and opensoure distribution for python and R programming.
      2. It is design for data-science, machine learning etc.
      3. It has package manager conda  
      4. Conda is used for installing and uninstalling package.
      5. Comes with pre-installed libries  like pandas, numpy, matplotlib, etc.
      6. It is cross platform - it is work on Windows, MacOS, Linux.

   2. Jupyter Notebook
      1. Jupyter is free and opensource webapplication.
      2. Work similarly like python shell.
      3. It allow us to write python code.
      4. It allow us to create and share document.
      5. Runs on browser
      6. Support inline visulaization with librires like Matplotlib and Seaborn.

   3. pip
      1. Pip is python default package manager.
      2. It comes with python install.
      3. It allow you to install, upgrade and manage python packages. 
      4. Use command pip install <package name> to install package
      5. Use command pip uninstall <package name> to unistall package
      6. Allow you install project dependency using pip install requirements.txt  

################################################################################################

9.   During analysis, how do you treat the missing values?
     1. Remove missing data
        - Drop rows or column with too many missing value.
     2. Inputs missing data
        - fill missing values N/A or mean, mediam , mode based on condition
        - write seperate script for that and execute carefully.
     3. Flag
        - Create new column which flag=True when there is missing values
        - this help you to identify missing value in data.
     4. Leave
        - some models handles missing values so you can leave as well based on your environment.

###############################################################################################
13.  How to drop rows that contain a missing value from a numpy array?

            import numpy as np
            array = np.array(
               [1,2,3],
               [4, np.nan, 6]
            )

            cleaned_array = array[~np.isnan(array).any(axis=1)]

            print(cleaned_array)

################################################################################################
50.  What is Neural Network?  Explain  Forward and backward propagation in neural network.
     Neural Network -
         -  Neural network is the model inspired by human brain, consist of inter-connected 
            neuron, used to learn pattern and make prediction from data.
     1. Forward propagation 
         1. It is the process of passing input data to network to get an output.
         2. It is used for generic prediction.
         3. It main goal to obtain final prediction from input data.
         4. The data flow is in Forward direction. 
         5. Start with input layer
         6. End with output layer with prediction
         7. It does not have loss funstion
         8. Use in prediction

     2. Backward propagation 
         1. It is the process of adjusting weights based on errors to minimize loss.
         2. It is used for learning or weight adjustment.
         3. It is main goal to optimize the model by reducing error while
            prediction.
         4. Data flow is in backward direction
         5. Start with output layer.
         6. End with input layer with updated weight.
         7. It has loss funtion.
         8. Use in model training.


###########################################################################################
40.  Explain Neural Network Fundamentals.
     Neural Network -
         -  Neural network is the model inspired by human brain, consist of inter-connected 
            neuron, used to learn pattern and make prediction from data.
      
      Process -
         1. Input layer -
            - REceives raw data.
         2. Hidden Layer -
            - Process data using weights, biases, and activation funtion to detect pattern.
         3. Output Layer -
            - Produce the final results.

      Components -
         1. Weight -Parameter that control data-flow between neurons.
         2. Activation Funtion - Help network to learn complex patterns.
         3. Loss function - Measures error in predictions.

      Training -
         1 Forward propagation
         2. Backward Propation.

      

##########################################################################################

35.  Write a note on Hbase.
     1. It is opensource, distributed database
     2. It is build on top of hadoop
     3. It is design for realtime, large-scale data
     4. It is insipired by GOOGLE Bigtable
     5. It is highly scalable.
     6. The data is stored in column wise not in row wise.

##########################################################################################
36.  Explain Data Wrangling with one example.
   -  Data Wrangling - It is process of cleaning and transforming data into sutable format for
      analysis or machine learning.

      Step in Wrangling 
        1. handle missing values
        2. Format data
        3. Remove Duplicate
        4. Transform data.

    Eg -
         -------------------------------
          Date       + Product + Amount  
         ------------+---------+--------
          11-10-2023 +    A    +   100    
          11-12-2023 +    B    +   nan    
          11-12-2023 +    A    +   100 
         -------------------------------

         Data after Wrangling
         
               .
         -------------------------------
          Date       + Product + Amount  
         ------------+---------+--------
          2023-11-10 +    A    +   100    
          2023-11-12 +    B    +   100    
         -------------------------------


       Key changes -
         1. change the date format
         2. Remove duplicate records
         3. Fill missing out values
         
##################################################################################################
39.  Write a note on SciKit-Learn.
     1. Scikit Learn is the most powerful roboust machine learning library in python.
     2. It is free and open-source.
     3. It is build upon Numpy, Scipy and matplotlib.
     4. It is also known as sklearn.
     5. It support data-modeling and data-visulaization as well.
     6. It provide both supervised and unsupervised algorithims.
     7. It is biginner friendly.
     8. Also can be used for data-anaylisis.

#############################################################################################
         
 47.  Explain Recommender Systems with example.
      -  Recommeder system suggest items (like product, movies, music) based on user preference
         and behaviours.
      -  It is divided into three types
            1. Collaborative Filtering
            2. Content based Filtering
            3. Hybrid Filtering.
      - 1. Collaborative Filtering 
            -  It further divided into
                  1. User based
                  2. Item based
            1. User based - 
               - Recommends items based on others user likes or most users likes
            2. Item based -
               - REcommends items based on user likes
      - 2. Content based Filtering 
            - Recommends items based on featere similarly to the user like before.
            eg - spotify suggest music based on genere.

      - 3. Hybrid 
           - It is combonation of both Collaborative filtering and Content based filtering.
 
      - 4. Example 
           Amazon - Recommends products based on purchase history.
           Netfilx - Suggest movies based on watched history.
           Spotify - Suggest music based on listining history.

###############################################################################################
57.  Explain Time Series with one example.
     - A time series is a sequence of data points measured at successive time intervals.
     - It helps analyze patterns over time, like trends, seasonality etc.

     For example - Monthly Sales Data.

                     +------------+------------+
                     | Month      | Sales ($)  |
                     +------------+------------+
                     | January    | 2000       |
                     | February   | 2200       |
                     | March      | 2500       |
                     | April      | 2800       |
                     | May        | 3000       |
                     | June       | 3500       |
                     | July       | 3800       |
                     | August     | 4200       |
                     | September  | 4300       |
                     | October    | 5000       |
                     | November   | 5500       |
                     | December   | 6000       |
                     +------------+------------+
        
        In this example 
         - Trend - sales are increase over time.
         - seasonality - Sales tend to increse toward end of the year
                       due to holidays seasons.
      Key component -
         Trend - Overall direction increase , decrease, sutable
         seasonality - Pattern that repeat after interval of time (eg, yearly, monthly)
         Noise - Random fluctuation or errors in data.

################################################################################################
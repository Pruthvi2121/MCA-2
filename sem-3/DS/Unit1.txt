

###########################################################################################################

2. What is data science ? Explain the role of Data Scienctist. 

  - Data Science 
      - Data Science is the study of data to find pattern, make prediction, and help in taking better
        desicions, It uses lools like Statistic, Algorithm, programming to convert data into usesful
        insights.

   - Role of Data  Scienctist.
        1. Data Collection
        2. Data Cleaning 
        3. Analyzes Data 
        4. Build Models 
        5. Data Visulization 
        6. Solve Business problem 

        1. Data Collection
           - Gather data from various sources include (database, API's, etc)
        2. Data Cleaning 
           - Clean data by fixing errors, finding missing values, organize it for analysis
        3. Analyzes Data -
           - Analyzes the data to find patterns and trends using statistics .
        4. Build Models -
           - Create Predictive models using machine learning.
        5. Data Visulization -
           - Visulize finding using ploting graphs, charts, etc 
             to help non-technical teams understand the results.
        6. Solve Business problem 
           - Collaborate with Business teams and provide insights and recommandation based on Research
             to make better desicions.

3. Describe any four  tools of data science.
    1. Python
    2. Pandas 
    3. Numpy
    4. Matplotlib
    5. Tableau
    6. SQL
 
 
    1. Python-
       - Popular programming lanaguage used for data-analysis and machine-learning
    2. Pandas -
       - Python libries to manage and anaylise data in tables (Dataframe)
    3. Numpy -
       - Python librires to perform numerical operation over datasets.
    4. Matplotlib -
       - Python libries for data Visulization using diffrent charts, dashborads, graphs, etc
    5. Tableau 
       - tool used to organize data 
    6. SQL -
        language for querying and managing data in relational databases
 


##########################################################################################################

4.   What is hadoop ? Explain Hadoop ecosystem with diagram.
    - Hadoop 
      1. Hadoop is an open-souce framework 
      2. It is used to store and process larage amount of data across diffent
         distributed computer environment.
    
    - components of Hadoop
                1. HDFS
                2. MapReduce
                3. YARN
                4. Hive
                5. Pig
                6. Mahout
                7. Zookeeper
                8. Oozie
         
        1. HDFS 
            -  HDFS stand for Hadoop Distributed File System.
            -  It is used for storing data accross multipal computer sytems.
        2. MapReduce
            - MapReduce is used for processing data parallel accross multipal computer Systems
        3. YARN 
            - YARN stands for Yet Another Resources Negotiator
            - It is a Resources management layer of hadoop for managing and scheduling jobs.
        4. Hive
           - It is SQL for Hadoop 
           - Allow you to querry data using sql-like lanaguage
             make it easier to interact with hadoop
        5. Pig -
            Tool that help you to write data processing script with knowing complex programming.

        6. Mahout 
           - Mahout provide machine learning algorithim to process data in hadoop.

        7.  Zookeeper 
           - Helps in cordination among diffrent distributed computer system
           - provide task synchronization over system.

        8.  Oozie -
           - It perform task of scheduling jobs               

         

Diagram -

                    +-----------------------+
                    |       Clients         |   --> (Applications or Users)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |     Data Ingestion    |   
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |    Data Storage       |   --> (HDFS)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |    Data Processing    |   --> (MapReduce, Hive, Pig)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |   Resource Management |   --> (YARN)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |   Machine Learning    |   --> (Mahout)
                    +-----------------------+
                            |
                            v
                    +-----------------------+
                    |    Workflow & Jobs    |   --> (Oozie, Zookeeper)
                    +-----------------------+

######################################################################################################

10.  Write a note on TensorFlow.
    1. TensorFlow is popular framework for deep-learning and Machine learning.
    2. It is free and opensource framework
    3. It is develop by google brain teams
    4. It is based on python programming lanaguage.
    5. It makes machine learning easier and faster.
    6. The word TensorFlow is made up of two words 
        1. Tensor
        2. Flow 
    7. Tensor stand for multi-diminsion array
    8. Flow stand for flow of data in operation

    Advantages 
            1. Easy to use
            2. Application
            3. Scalable
            4. Machine Leaning and Deeplearning

      1 Easy to use
         - It is biginner friendly framework.
      2. Application -
        - It has wide range of applications
        - It is used in image recognation, speech recognation, natural lanaguage processing etc.
      3. Machine Learning and Deeplearning 
        - It is mainly used for deep learning but can be also used for machine leaning task.
      4. Scalable -
        - It is highly scalable it can run on both CPU and GPU
          even in mobile device.
      
#########################################################################################################

11.  Write a note on SciPy 
     1. Scipy stands for Scientifc Python
     2. It is free and opensource Framework
     3. It is based on python programming lanaguage.
     4. It is scientific computational libries of python uses numpy underneath.
     5. It is used for solving complex scientific and mathematical problems.
     6. It provide various functions for data optmizations, integrations, analysis.

     Feature -       
       1. Easy to use 
       2. Wide Application
       3. Large Community support
       4. Build over Numpy

       1. Easy to use 
         - SciPy is biginner friendly framework.

       2. Wide Application
         - It has wide range of applications in fields of data-science, biology, physics etc
           for solving mathematical and computational problems.

       3. Large Community support
         - It has large Community

       4. Build over Numpy
         - It is build over Numpy and extend the power of numpy.
     
########################################################################################################

12.  What is Numpy ? Explain its features.
    1. Numpy stand for numerical python
    2. Numpy is free and open source python libries
    3. Numpy is genral purpose python package to handle arrays
    4. Numpy support multi-dimenstion array.
    5. Numpy array is 50x faster than traditional python list
    6. Numpy written in python , c and c++ which increase its performance

  Feature -
            1. Performance
            2. Easy to Use
            3. Memory Efficent
            4. Multi-Dimention Array
            5. Open-source
            6. Mathematical function
            
    1. Performance -
       - Numpy is faster that Python List.
    2. Easy to Use -
       - Numpy syntax is easy to use and user friendly
    3. Memory Efficent 
       - Numpy uses Less memory compare to python build in data-structure.
    4. Multi-Dimention Array
       - Numpy support Multi-dimenstion array.
    5. Open-source 
       - Numpy is free and open source python package.
    6. Mathematical function
       - Provide wide range of mathematical funtion such as trignometric function,
         logarithmic function, exponatinal, sqare-root etc.

####################################################################################################################

27.  Write a note on Seabon.
     1. Seaborn is powerful data-visulization package
     2. It is free and open-source
     3. Seaborn is based on Matplotlib
     4. It support all the feature of Matplotlib
     5. It is easy and bigineer friendly package
     6. It provide set of default theme and color which 
        make it attractive .
     7. It work seamlessly with pandas dataframe.
     8. Simplify complex process of data-visulization into 
        few lines of code.

#######################################################################################
29.  Write a note on HDFS.
     1. HDFS stand for Hadoop distributed file system.
     2. Hadoop come with distributed file system called HDFS
     3. It is cost efficent
     4. It work on low cost hardware. 
     5. It is highly scalable models
     6. It is ideal for large file.

     Components of HDFS
       1. Block
       2. Name Node
       3. Data Node
      1. Block -
        - Block store the data 
        - It has default 128 mb memory

      2.Name Node
        - Name Node manage the file-system meta-data (like, name, permission, etc)
      3. Data Node
        - they store the data blocks
        - they retrive and send blocks when request by client.
        
###########################################################################################
53.  Write a note on matplotlib.
     1. Matplotlib is powerful data-visulization package.
     2. It is free and open-source
     3. It used in data-visulization task.
     4. It support varous plotting include
        - line plots.
        - scatter plots
        - graphs
        - charts,
        - histogram , etc
     5. It is easy and bigineer friendly package
     6. Simplify complex process of data-visulization into 
        few lines of code.
      
###########################################################################################

42.  Write a note Keras.

   1. Keras is popular and powerful framework for Neural Network.
   2. It is free and opensource
   3. It is develop by one google engineering
   4. It is based on python programming.
   5. It is highly scalable it can run on both CPU and GPU 
   6. Support any Architecture.
   7. It is easy to learn package
   8. It is easy to use package make it 
   9. Support fast proto-typing.

############################################################################################

43.  Write a note on Pytorch.
    1. Pytourch is popular framework for for deeplearning.
    2. It is free and opensource framework
    3. It is build using  python programming.
    4. It is develop by facebook.
    5. It is easy to use framework
    6. It is based on torch libries.
    7. Pytorch is completly pythonic
    8. Easy to create neural network models
    9. It is easy in building an extreme complex neural network.
    10. Higly flexible , we can use it as per are requirements.

#############################################################################################

44.  Write a note on AutoML.
    1. AutoML stands for Automated Machine Learning.
    2. It is the process of automating the process of 
       machine learning to solve real world problems.
    3. AutoML is a technology that automates the process of building machine learning models
    4. It allow people without expertise in machine learning to create powerful machine learning models.
    5. It automate the manual task required for building model and 
       save time.
    6. This are some automML platforms
        1. Google Cloud AutoML.
        2. Microsoft Auzure AutoML 
        3. AWS AutoML., etc.

##############################################################################################

58.  Write a note on Colab and Kaggle.
   Coalb -
     1. Google Colab is free and opensource online tool.
     2. It is use to run and write python code.
     3. Provide free access to GPU.
     4. No need to setup, everything is ready to use.
     5. Supprot Python libries like TensorFlow, Pytorch, etc.
     6. Can able to share via link.

   Kaggle -
     1. Kaggel is also free and opensource online tool
     2. It also provide free access to GPU.
     3. Run in browser,
     4. We are able to share our code via link
     5. Write and run code online. 
     6. Best for datastes 

#################################################################################################
48.  Write a note on Artificial Neural Network. ANN
49.  Write a note on Convolutional Neural Network. CNN

   1. Artificial Neural Network -
      1. It does not allow paramter sharing.
      2. Work with tabular data and text data.
      3. Required fixed input
      4. ANN can experience vanishing.
      5. Does not Capture spatial relationships
      6. Less powerfull compare to CNN.

      Application - 
         Eg- . Used in face recognation, computer vision.

   2. Convolutional Neural Network
      1. It allow paramter sharing.
      2. Work with image data.
      3. Required fixed input in forms of image.
      4. CNN can experience vanishing.
      5. Capture spatial relationships.
      6. More powerfull compare to ANN.

      Application -
         Eg - Image recognation, Computer vision.

################################################################################################
37.  Write a note on machine learning lifecycle.

      1. Collect Data: 
         -  Collect necessary data.
      2. Clean Data:
         -  Clean and format data.
      3. Select Model: 
         - Choose an algorithm.
      4. Train Model: 
         - Train the model on the data.
      5. Evaluate Model: 
         - Check the model's performance.
      6. Tune Model: 
         - Optimize settings to improve accuracy.
      7. Deploy Model
         - Put the model into use.
      8. Monitor Model:
         - Monitor the model to keep it up to date.

################################################################################################
19.  Write a note on Anaconda and Jupyter Notebook and pip.
   1. Anaconda -
      1. Anaconda is free and opensoure distribution for python and R programming.
      2. It is design for data-science, machine learning etc.
      3. It has package manager conda  
      4. Conda is used for installing and uninstalling package.
      5. Comes with pre-installed libries  like pandas, numpy, matplotlib, etc.
      6. It is cross platform - it is work on Windows, MacOS, Linux.

   2. Jupyter Notebook
      1. Jupyter is free and opensource webapplication.
      2. Work similarly like python shell.
      3. It allow us to write python code.
      4. It allow us to create and share document.
      5. Runs on browser
      6. Support inline visulaization with librires like Matplotlib and Seaborn.

   3. pip
      1. Pip is python default package manager.
      2. It comes with python install.
      3. It allow you to install, upgrade and manage python packages. 
      4. Use command pip install <package name> to install package
      5. Use command pip uninstall <package name> to unistall package
      6. Allow you install project dependency using pip install requirements.txt  

################################################################################################

9.   During analysis, how do you treat the missing values?
     1. Remove missing data
        - Drop rows or column with too many missing value.
     2. Inputs missing data
        - fill missing values N/A or mean, mediam , mode based on condition
        - write seperate script for that and execute carefully.
     3. Flag
        - Create new column which flag=True when there is missing values
        - this help you to identify missing value in data.
     4. Leave
        - some models handles missing values so you can leave as well based on your environment.

###############################################################################################
13.  How to drop rows that contain a missing value from a numpy array?

            import numpy as np
            array = np.array(
               [1,2,3],
               [4, np.nan, 6]
            )

            cleaned_array = array[~np.isnan(array).any(axis=1)]

            print(cleaned_array)

################################################################################################
Q1. Which variables should we include in a regression model? 
    1. Dependent variable (Y):
       - The outcome you want to predict.
    2. Independant variable (X)
       - The predictors or features that influence (affect) the dependent variable.
    3. Control variable 
       - Account for other influencing factors
    4. Dummy variables -
       - To represent categorical data.   
    5. Interaction terms
       - Joint effects of variables.

###########################################################################################
Q2. Explain VIF (Variance Inflation Factor).
    1. VIF - Stand fro Variance INflation Factor
    2. Defincation - Varience Inflation Fator (VIF) measure how much predictor varience increased with corelation with other predictor.

    VIF Conditions
        1. VIF = 1
          - when VIF = 1 , NO correlation with other variables.
        2. VIF > 1
          - When VIF is greater than one , Correlation with other variables.
        3. VIF > 5 or 10
          - when VIF greater than 5 or 10, Indicate problematic multicollinearity,
            which may require action like removing or combining variables.

#################################################################################################
Q3. What are the impacts on regression model?
    1. High standard Errors    
       - Hard to find important predictors
    2. Unstable coefficient
       - Unstable coefficient can lead inconsistent result.
    3. Hard to Understand 
       - Hard to understand each predictor effects
    4. Overfitting
       - Model may overfit while working with new data.
    5. Wrong conclusion
       - Mislead result and insight.

#####################################################################################################
Q7.Explain the Akaike information criterion (AIC)
  1. AIC stand for Akaike information criterison
  2. Akaike information criterison is a measeure to compare diffrent models
  3. It help to balance model fit and complexity
  4. AIC goal is to find the model which fit the data well and which is less complex.

  Formula -
          AIC =  2k − 2ln (L)

  Conditions 
    1. Lower AIC - Indicate A better model, with less complex 
    2. Higher AIC - Indicate more complex model and can overfit data.

################################################################################################
Q8. What is polynomial linear regression.
Q10.What is the polynomial regression is non – local

    1. Defination - Polynominal Linear Regression fit curve to data by adding powers of predictors like ( x3, x4 )
    2. For Example -

       Linear Y = B0 + B1X    # down power
       Polynomial Y = B0 + B1X + B2X2 + B2X3 ....  

    3. Polynomial Regression is non-local beacuse they uses higher degree terms 
       eg - x3 , x4
       Due to this model allow to find out global trends not just local trends

##############################################################################################################
Q9. What is the physical significance of coefficients.
   1. Scaling Factor -
      show how one thing affect another
      example F = ma  //  here m shows how much force is needed for a given acceleration.

    2. Physical Properties
       - Represent characterstic of material
       example  F = kx   // here k is spring stiffness

    3. Rate/constant-
       - Tell how fast something happen
       example:  d = v x t   // distance = velocity * time
       here d show rate of change of distnce with time.

    4. Unit converter
       - Keep equeation correct in Unit
        Example - KE = 1/2 mv2    here 1/2 adjust the units

####################################################################################################
Q4. What is the stratification technique and explain with example.
   1. Stratification is a quality control tool used to separate data into different groups 
      to understand patterns or problems more clearly. 
   2. It help you to find the real cause of problem.
   3. Stratification = Sorting data into groups to find hidden problems.

   Examle -
      A company find defect in his Products, to find cause of it, 
      - Its stratifies defect data by shift

            Shift                     Defect Found
     -----------------------------------------------------       
            Morning          |            2
            Afternoon        |            3
            Night            |            12
     -----------------------------------------------------

      Analysis - 
          Most Defect happen in Night shift.
         
      Now, the company knows where to investigate further.

#########################################################################################################
# Q1 Write a note on SLR.

  Concept -
   1. Multiple Linear Regression is used to predict a dependent variable (Y) from two or more independent variables 
     (X₁, X₂, ..., Xn).
     

   2. It assumes a linear relationship between the dependent variable and all independent variables.
   3. B₀, B₁, B₂, ..., Bn are the main parameters of multiple linear regression.

   Equation 
       Y = B₀ + B₁X₁ + B₂X₂ + ... + BnXn

       Where,
         Y = Dependant Varable    (what you are goint to predict)
         X₁, X₂, ..., Xn    =    Independent Variables  (Input or feature)
         B₀                 =    Intercept         (Value of Y when all x = 0)
         B₁, B₂, ..., Bn    =    Coefficients/Slope           

#########################################################################################################
Q3 What is a PLR ? Explain it with an example.
   1. Polynomial Linear Regression is used to model a non-linear relationship 
      between the dependent variable (Y) and the independent variable (X).
   2. It transforms the input features into higher-degree polynomial terms (like X², X³, etc.) 
   3. Althought the relastionship is non-linear but still the PLR are considered as type of Linear Model
       because it is linear in the coefficients (B₀, B₁, B₂, ...).


   Equation -
    Y = B₀ + B₁X + B₂X² + B₃X³ + ... + BnXⁿ

   Where:
      Y = Dependent Variable  (what you are going to predict)

      X = Independent Variable  (input or feature)

      X², X³, ..., Xⁿ = Polynomial terms of X

      B₀ = Intercept  (value of Y when X = 0)

      B₁, B₂, ..., Bn = Coefficients for each power of X (control shape of the curve)




      Python Example
      --------------------------------------------------------------

      from sklearn.linear_model import LinearRegression
      from sklearn.preprocessing import PolynomialFeatures
      import numpy as np

      X = [[1], [2], [3]]
      y = [1, 4, 9]

      X_poly = PolynomialFeatures(degree=2).fit_transform(X)
      model = LinearRegression().fit(X_poly, y)
      print(model.predict(X_poly))


#############################################################################################################
Q7 What are the pros and cons of decision tree model?
Q6 How decision tree is used for regression?

    Defination 
       - A decision tree is a model used to make decisions by splitting data based on features, forming a tree structure
   
    Advantage -
      1. Easy to understand
      2. Data scalling not required
      3. handle both numerical and categorical data.
      4. Can model both linear and non-linear relastionship.
      5. Useful for feature importance analysis


    Disadvantages
      1. Overfitting with complex Trees
      2. Sensitive to small change in data
      3. Can be bias toward dominant classes.


      Working -
        Split the data 
              |
        Nodes test the feature 
              |
        Prediction

###############################################################################################################
Q8 How KNN is used for regression problem?
Q10 Why KNN is called as lazy algorithm?
Q11 How KNN is work?

   1. KNN stands for Kth nearest Neighbors KNN
   2. KNN is simple instance based learning algorithm 
   3. It is used for regression and classifications

   Working -
     1. Find the kth nearest neighbours
        - Given new points , KNN calculate distance from given points to each points
     2. Select K closest point
        - Algorithm find the closest kth point which is nearest to the given point
     3. Make Prediction 
        - Classification - Majority class which are near to k neighbour are predicted class
        - Regressions - The average (mean) of the K neighbors' values is the predicted value.


    KNN called lazy
    4.  It is also know as lazy algorithm
        1. It not have learning phase or steps
        2. It doest build model during Training
           Instead it memoris the entire dataset
        3. Computes Prediction at Runtime

        4. In short KNN does all work while prediction, making it lazy compare to other algorithms.

##########################################################################################################

Q9 What is the difference between instance based learning and model based 
learning?

 Instance based Learning  

1.  No training phase                      
2.  Used entire dataset for prediction      
3.  Example - KNN                           
4.  Adapt new data quickly                 
5.  Cannot handle large dataset efficently   
6.  Not memory efficient 
7.  computational expense increase as dataset increase
8.  It is sensitive to noisy data.

Model Based learning

  1. It has training phase
  2. Use model for prediction
  3. Example - SLR, MLR, Decision Tree
  4. Cannot Adapt new data quickly
  5. It can handle large datasets more efficiently.
  6. It is memory efficent save memory
  7. computational expense remain constant.
  8. It is less sensitive to noisy data.

####################################################################################################
